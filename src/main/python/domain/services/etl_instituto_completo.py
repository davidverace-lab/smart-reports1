"""
Sistema ETL Completo - Instituto Hutchison Ports
================================================

Sistema de Extracci√≥n, Transformaci√≥n y Carga (ETL) para procesar archivos Excel
de CSOD (Cornerstone OnDemand) y cargarlos en SQL Server.

Caracter√≠sticas:
- ‚úÖ Soporte para SQL Server (pyodbc)
- ‚úÖ Validaci√≥n de datos con Pydantic
- ‚úÖ Auto-detecci√≥n de m√≥dulos nuevos (escalable a 14+ m√≥dulos)
- ‚úÖ Batch operations para alto rendimiento
- ‚úÖ Detecci√≥n autom√°tica de columnas (Espa√±ol/Ingl√©s)
- ‚úÖ Matching case-insensitive para m√≥dulos y evaluaciones
- ‚úÖ Manejo robusto de errores y logging
- ‚úÖ Soporte para ambos archivos: Training Report y Org Planning

Archivos soportados:
1. Enterprise_Training_Report{timestamp}.xlsx
2. CSOD_Data_Source_for_Org_Planning_{timestamp}.xlsx

Autor: Claude AI
Fecha: 2025-01-18
Versi√≥n: 1.0.0
"""

import pandas as pd
import pyodbc
import re
import unicodedata
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any, Set
from dataclasses import dataclass
from enum import Enum
import logging
from difflib import SequenceMatcher

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================================
# PYDANTIC MODELS - VALIDACI√ìN DE DATOS
# ============================================================================

try:
    from pydantic import BaseModel, Field, validator, ValidationError
except ImportError:
    logger.warning("‚ö†Ô∏è  Pydantic no instalado. Instalando con: pip install pydantic")
    # Fallback a dataclasses si no hay Pydantic
    BaseModel = object


class EstatusModulo(str, Enum):
    """Estados posibles de un m√≥dulo"""
    TERMINADO = "Terminado"
    EN_PROGRESO = "En progreso"
    REGISTRADO = "Registrado"
    NO_INICIADO = "No iniciado"


class TipoCapacitacion(str, Enum):
    """Tipos de capacitaci√≥n"""
    CURRICULUM = "Curriculum"
    PRUEBA = "Prueba"


class UsuarioExcel(BaseModel):
    """Modelo de validaci√≥n para datos de usuario del Excel"""
    user_id: str = Field(..., min_length=1, description="ID √∫nico de usuario (MASTER KEY)")
    nombre_completo: Optional[str] = None
    email: Optional[str] = None
    cargo: Optional[str] = None  # Position
    unidad_negocio: Optional[str] = None
    departamento: Optional[str] = None
    ubicacion: Optional[str] = None
    nivel: Optional[str] = None

    @validator('user_id')
    def user_id_no_vacio(cls, v):
        if not v or v.strip() == '':
            raise ValueError('user_id no puede estar vac√≠o')
        return v.strip()

    @validator('email')
    def validar_email(cls, v):
        if v and '@' not in v:
            logger.warning(f"Email potencialmente inv√°lido: {v}")
        return v


class ProgresoModuloExcel(BaseModel):
    """Modelo de validaci√≥n para progreso de m√≥dulo"""
    user_id: str = Field(..., min_length=1)
    titulo_capacitacion: str = Field(..., min_length=1)
    tipo_capacitacion: Optional[str] = None
    estado: Optional[str] = None
    fecha_inicio: Optional[datetime] = None
    fecha_finalizacion: Optional[datetime] = None
    fecha_registro: Optional[datetime] = None
    puntuacion: Optional[float] = None

    @validator('puntuacion')
    def validar_puntuacion(cls, v):
        if v is not None and (v < 0 or v > 100):
            raise ValueError(f'Puntuaci√≥n fuera de rango: {v}')
        return v


# ============================================================================
# CONFIGURACI√ìN Y CONSTANTES
# ============================================================================

@dataclass
class ETLConfig:
    """Configuraci√≥n del ETL"""
    # SQL Server
    server: str = "localhost"
    database: str = "InstitutoHutchison"
    username: Optional[str] = None  # Si es None, usa autenticaci√≥n Windows
    password: Optional[str] = None
    driver: str = "ODBC Driver 17 for SQL Server"

    # ETL Settings
    batch_size: int = 1000
    enable_validation: bool = True
    auto_create_modules: bool = True

    # Defaults
    default_puntaje_minimo: float = 70.0
    default_intentos_permitidos: int = 3
    default_rol_id: int = 4  # Usuario


# Mapeo completo de los 14 m√≥dulos
MODULOS_MAPPING = {
    1: "M√ìDULO 1 . INTRODUCCI√ìN A LA FILOSOF√çA HUTCHINSON PORTS",
    2: "M√ìDULO 2 . SOSTENIBILIDAD, NUESTRO COMPROMISO CON EL FUTURO",
    3: "M√ìDULO 3 . INTRODUCCI√ìN A LAS OPERACIONES",
    4: "M√ìDULO 4 . RELACIONES LABORALES",
    5: "M√ìDULO 5 . SEGURIDAD EN LAS OPERACIONES",
    6: "M√ìDULO 6 . CIBERSEGURIDAD",
    7: "M√ìDULO 7 . ENTORNO LABORAL SALUDABLE",
    8: "M√ìDULO 8 . PROCESOS DE RECURSOS HUMANOS",
    9: "M√ìDULO 9 . PROGRAMAS DE BIENESTAR INTEGRAL",
    10: "M√ìDULO 10 . DESARROLLO DE NUEVOS PRODUCTOS",
    11: "M√ìDULO 11 . PRODUCTOS DIGITALES DE HP",
    12: "M√ìDULO 12 . TECNOLOG√çA: IMPULSO PARA LA EFICIENCIA Y PRODUCTIVIDAD",
    13: "M√ìDULO 13 . ACTIVACI√ìN DE PROTOCOLOS Y BRIGADAS DE CONTINGENCIA",
    14: "M√ìDULO 14 . SISTEMA INTEGRADO DE GESTI√ìN DE CALIDAD Y MEJORA CONTINUA"
}

# Mapeo de evaluaciones a m√≥dulos (case-insensitive)
EVALUACIONES_A_MODULOS = {
    # M√≥dulo 1
    "introducci√≥n a la filosof√≠a": 1,
    "filosof√≠a hutchinson": 1,

    # M√≥dulo 2
    "sostenibilidad": 2,
    "compromiso con el futuro": 2,

    # M√≥dulo 3
    "introducci√≥n a las operaciones": 3,
    "operaciones portuarias": 3,

    # M√≥dulo 4
    "relaciones laborales": 4,

    # M√≥dulo 5
    "seguridad en las operaciones": 5,
    "seguridad operacional": 5,

    # M√≥dulo 6
    "ciberseguridad": 6,
    "seguridad inform√°tica": 6,

    # M√≥dulo 7
    "entorno laboral saludable": 7,
    "salud laboral": 7,

    # M√≥dulo 8
    "procesos de recursos humanos": 8,
    "recursos humanos": 8,
    "rrhh": 8,

    # M√≥dulo 9
    "programas de bienestar": 9,
    "bienestar integral": 9,

    # M√≥dulo 10
    "desarrollo de nuevos productos": 10,
    "nuevos productos": 10,

    # M√≥dulo 11
    "productos digitales": 11,
    "digitales de hp": 11,

    # M√≥dulo 12
    "tecnolog√≠a": 12,
    "eficiencia y productividad": 12,

    # M√≥dulo 13
    "protocolos y brigadas": 13,
    "brigadas de contingencia": 13,

    # M√≥dulo 14
    "sistema integrado": 14,
    "gesti√≥n de calidad": 14,
    "mejora continua": 14
}

# Variaciones de columnas (Espa√±ol/Ingl√©s)
COLUMN_VARIATIONS = {
    'user_id': [
        'Identificaci√≥n de usuario',
        'User ID',
        'User Identification',
        'ID',
        'UserId'
    ],
    'training_title': [
        'T√≠tulo de la capacitaci√≥n',
        'T√≠tulo de capacitaci√≥n',
        'Training Title',
        'Course Title',
        'Title'
    ],
    'training_type': [
        'Tipo de capacitaci√≥n',
        'Training Type',
        'Content Type',
        'Type'
    ],
    'record_status': [
        'Estado del expediente',
        'Record Status',
        'Completion Status',
        'Status',
        'Estatus'
    ],
    'transcript_date': [
        'Fecha de registro de la transcripci√≥n',
        'Transcript Registration Date',
        'Registration Date',
        'Fecha de Registro'
    ],
    'start_date': [
        'Fecha de inicio de la capacitaci√≥n',
        'Training Start Date',
        'Start Date',
        'Fecha de Inicio'
    ],
    'completion_date': [
        'Fecha de finalizaci√≥n de expediente',
        'Record Completion Date',
        'Completion Date',
        'Finished Date',
        'Fecha de Finalizaci√≥n'
    ],
    'score': [
        'Puntuaci√≥n de la transcripci√≥n',
        'Transcript Score',
        'Score',
        'Grade',
        'Calificaci√≥n'
    ],
    'full_name': [
        'Nombre completo del usuario',
        'User - Full Name',
        'Full Name',
        'Name',
        'Nombre Completo'
    ],
    'email': [
        'Correo electr√≥nico del usuario',
        'User - Email Address',
        'Email',
        'E-mail',
        'Correo'
    ],
    'position': [
        'Usuario - Cargo',
        'Cargo',
        'Position',
        'Job Title'
    ],
    'business_unit': [
        'Usuario - Divisi√≥n',
        'Divisi√≥n',
        'Unidad de negocio',
        'User - Division',
        'Business Unit',
        'Division'
    ],
    'department': [
        'Usuario - Departamento',
        'Departamento',
        'Department',
        'Organization'
    ],
    'location': [
        'Usuario - Ubicaci√≥n',
        'Ubicaci√≥n',
        'User - Location',
        'Location',
        'Site'
    ],
    'level': [
        'Usuario - Nivel',
        'Nivel',
        'User - Level',
        'Level'
    ]
}

# Mapeo de estados del Excel a estados de BD
ESTADO_MAPPING = {
    'terminado': EstatusModulo.TERMINADO,
    'completado': EstatusModulo.TERMINADO,
    'completed': EstatusModulo.TERMINADO,
    'finished': EstatusModulo.TERMINADO,
    'en progreso': EstatusModulo.EN_PROGRESO,
    'in progress': EstatusModulo.EN_PROGRESO,
    'progress': EstatusModulo.EN_PROGRESO,
    'registrado': EstatusModulo.REGISTRADO,
    'registered': EstatusModulo.REGISTRADO,
    'enrolled': EstatusModulo.REGISTRADO,
    'no iniciado': EstatusModulo.NO_INICIADO,
    'not started': EstatusModulo.NO_INICIADO,
    'pending': EstatusModulo.NO_INICIADO
}

# Porcentaje por estado
PORCENTAJE_POR_ESTADO = {
    EstatusModulo.TERMINADO: 100,
    EstatusModulo.EN_PROGRESO: 50,
    EstatusModulo.REGISTRADO: 0,
    EstatusModulo.NO_INICIADO: 0
}


# ============================================================================
# CLASE PRINCIPAL ETL
# ============================================================================

class ETLInstitutoCompleto:
    """
    Sistema ETL completo para procesar archivos Excel de CSOD

    Flujo del proceso:
    1. Extracci√≥n: Leer Excel con detecci√≥n autom√°tica de headers
    2. Validaci√≥n: Validar datos con Pydantic
    3. Transformaci√≥n: Normalizar, mapear y enriquecer datos
    4. Carga: Insertar/actualizar en SQL Server con batch operations
    5. Reporte: Generar estad√≠sticas de la importaci√≥n
    """

    def __init__(self, config: ETLConfig):
        """
        Inicializa el sistema ETL

        Args:
            config: Configuraci√≥n del ETL
        """
        self.config = config
        self.connection: Optional[pyodbc.Connection] = None
        self.cursor: Optional[pyodbc.Cursor] = None

        # Columnas detectadas en el Excel
        self.detected_columns: Dict[str, str] = {}

        # Cach√©s para optimizaci√≥n (evitar N+1 queries)
        self._cache_modulos: Dict[str, int] = {}
        self._cache_evaluaciones: Dict[int, int] = {}
        self._cache_unidades: Dict[str, int] = {}
        self._cache_departamentos: Dict[Tuple[int, str], int] = {}
        self._cache_usuarios: Dict[str, int] = {}
        self._cache_progresos: Dict[Tuple[str, int], int] = {}

        # Estad√≠sticas
        self.stats = {
            'usuarios_nuevos': 0,
            'usuarios_actualizados': 0,
            'progresos_insertados': 0,
            'progresos_actualizados': 0,
            'calificaciones_registradas': 0,
            'modulos_creados': 0,
            'evaluaciones_creadas': 0,
            'unidades_creadas': 0,
            'departamentos_creados': 0,
            'errores': [],
            'tiempo_inicio': None,
            'tiempo_fin': None
        }

        # Conectar a BD
        self._conectar_bd()

    # ========================================================================
    # CONEXI√ìN A BASE DE DATOS
    # ========================================================================

    def _conectar_bd(self):
        """Establece conexi√≥n con SQL Server"""
        try:
            # Construir connection string
            if self.config.username and self.config.password:
                # Autenticaci√≥n SQL Server
                conn_str = (
                    f"DRIVER={{{self.config.driver}}};"
                    f"SERVER={self.config.server};"
                    f"DATABASE={self.config.database};"
                    f"UID={self.config.username};"
                    f"PWD={self.config.password};"
                )
            else:
                # Autenticaci√≥n Windows
                conn_str = (
                    f"DRIVER={{{self.config.driver}}};"
                    f"SERVER={self.config.server};"
                    f"DATABASE={self.config.database};"
                    f"Trusted_Connection=yes;"
                )

            self.connection = pyodbc.connect(conn_str, autocommit=False)
            self.cursor = self.connection.cursor()

            logger.info(f"‚úÖ Conectado a SQL Server: {self.config.server}/{self.config.database}")

        except Exception as e:
            logger.error(f"‚ùå Error conectando a SQL Server: {e}")
            raise

    def cerrar_conexion(self):
        """Cierra la conexi√≥n a la BD"""
        if self.cursor:
            self.cursor.close()
        if self.connection:
            self.connection.close()
        logger.info("üîí Conexi√≥n cerrada")

    def __enter__(self):
        """Context manager entry"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit"""
        self.cerrar_conexion()

    # ========================================================================
    # EXTRACCI√ìN: LECTURA Y DETECCI√ìN DE EXCEL
    # ========================================================================

    def _leer_excel_con_deteccion_headers(self, archivo_excel: str) -> pd.DataFrame:
        """
        Lee Excel detectando autom√°ticamente d√≥nde est√°n los headers reales

        CSOD a veces pone metadatos en las primeras filas. Esta funci√≥n
        detecta autom√°ticamente d√≥nde comienzan los datos reales.

        Args:
            archivo_excel: Ruta al archivo Excel

        Returns:
            DataFrame con los datos
        """
        try:
            # Intentar lectura normal
            df = pd.read_excel(archivo_excel, engine='openpyxl')

            # Verificar si los headers son v√°lidos
            if any('Unnamed' in str(col) for col in df.columns):
                logger.warning("‚ö†Ô∏è  Headers no detectados en fila 0, buscando headers reales...")

                # Buscar headers reales en las primeras 10 filas
                for skip_rows in range(1, 11):
                    try:
                        df_test = pd.read_excel(archivo_excel, skiprows=skip_rows, engine='openpyxl')

                        # Verificar si encontramos columnas conocidas
                        cols_str = ' '.join(str(c).lower() for c in df_test.columns)
                        keywords = ['usuario', 'user', 'm√≥dulo', 'module', 'training', 'capacitaci√≥n']

                        if any(kw in cols_str for kw in keywords):
                            logger.info(f"‚úÖ Headers encontrados en fila {skip_rows}")
                            return df_test
                    except:
                        continue

                logger.warning("‚ö†Ô∏è  No se pudieron detectar headers autom√°ticamente. Usando fila 0.")
                return df

            return df

        except Exception as e:
            logger.error(f"‚ùå Error leyendo Excel {archivo_excel}: {e}")
            raise

    def _detectar_columnas(self, df: pd.DataFrame) -> Dict[str, str]:
        """
        Detecta autom√°ticamente las columnas del Excel (Espa√±ol/Ingl√©s)

        Args:
            df: DataFrame de pandas

        Returns:
            Diccionario con columnas detectadas {key: nombre_columna_excel}
        """
        self.detected_columns = {}
        columnas_excel = df.columns.tolist()

        for key, variations in COLUMN_VARIATIONS.items():
            for variation in variations:
                for col_excel in columnas_excel:
                    # Matching case-insensitive y con tolerancia a espacios
                    if variation.lower().strip() in str(col_excel).lower().strip():
                        self.detected_columns[key] = col_excel
                        break
                if key in self.detected_columns:
                    break

        logger.info(f"‚úÖ Columnas detectadas: {len(self.detected_columns)}/{len(COLUMN_VARIATIONS)}")

        # Mostrar columnas no detectadas
        no_detectadas = set(COLUMN_VARIATIONS.keys()) - set(self.detected_columns.keys())
        if no_detectadas:
            logger.info(f"‚ÑπÔ∏è  Columnas opcionales no encontradas: {', '.join(no_detectadas)}")

        return self.detected_columns

    # ========================================================================
    # TRANSFORMACI√ìN: NORMALIZACI√ìN Y UTILIDADES
    # ========================================================================

    @staticmethod
    def _normalizar_texto(texto: str) -> str:
        """
        Normaliza texto para matching case-insensitive

        - Convierte a min√∫sculas
        - Quita acentos
        - Quita espacios extras

        Args:
            texto: Texto a normalizar

        Returns:
            Texto normalizado
        """
        if not texto or pd.isna(texto):
            return ""

        # Convertir a string y min√∫sculas
        texto = str(texto).lower().strip()

        # Quitar acentos
        texto = ''.join(
            c for c in unicodedata.normalize('NFD', texto)
            if unicodedata.category(c) != 'Mn'
        )

        # Normalizar espacios
        texto = re.sub(r'\s+', ' ', texto)

        return texto

    @staticmethod
    def _extraer_numero_modulo(titulo: str) -> Optional[int]:
        """
        Extrae el n√∫mero de m√≥dulo del t√≠tulo usando regex

        Soporta variaciones como:
        - "M√ìDULO 8 - PROCESOS DE RRHH"
        - "Modulo 8: Procesos"
        - "MODULE 8 Procesos"

        Args:
            titulo: T√≠tulo del m√≥dulo/capacitaci√≥n

        Returns:
            N√∫mero del m√≥dulo (1-14) o None si no se encuentra
        """
        if not titulo or pd.isna(titulo):
            return None

        # Buscar "M√ìDULO X" o "MODULE X" (case-insensitive)
        match = re.search(r'M[O√ì]DULO\s+(\d+)', str(titulo), re.IGNORECASE)
        if match:
            num = int(match.group(1))
            if 1 <= num <= 14:
                return num

        return None

    def _identificar_modulo_fuzzy(self, titulo: str) -> Optional[int]:
        """
        Identifica m√≥dulo usando fuzzy matching si regex falla

        √ötil para t√≠tulos que no tienen "M√ìDULO X" pero mencionan el tema
        Ejemplo: "Ciberseguridad - Prueba Final" ‚Üí M√≥dulo 6

        Args:
            titulo: T√≠tulo de la capacitaci√≥n

        Returns:
            N√∫mero del m√≥dulo o None
        """
        titulo_norm = self._normalizar_texto(titulo)

        # Buscar en mapeo de evaluaciones
        for key, num_modulo in EVALUACIONES_A_MODULOS.items():
            if key in titulo_norm:
                return num_modulo

        # Fuzzy matching con nombres de m√≥dulos (umbral 80%)
        best_match_score = 0
        best_match_num = None

        for num, nombre in MODULOS_MAPPING.items():
            nombre_norm = self._normalizar_texto(nombre)
            score = SequenceMatcher(None, titulo_norm, nombre_norm).ratio()

            if score > best_match_score and score >= 0.8:
                best_match_score = score
                best_match_num = num

        if best_match_num:
            logger.info(f"üîç Fuzzy match: '{titulo}' ‚Üí M√≥dulo {best_match_num} (score: {best_match_score:.2f})")

        return best_match_num

    def _normalizar_estatus(self, estatus_excel: str) -> str:
        """
        Normaliza el estado del Excel al formato de la BD

        Args:
            estatus_excel: Estado del Excel

        Returns:
            Estado normalizado (enum)
        """
        if not estatus_excel or pd.isna(estatus_excel):
            return EstatusModulo.NO_INICIADO.value

        estatus_norm = self._normalizar_texto(estatus_excel)

        for key, enum_value in ESTADO_MAPPING.items():
            if key in estatus_norm:
                return enum_value.value

        # Default
        return EstatusModulo.NO_INICIADO.value

    def _calcular_porcentaje_por_estado(self, estatus: str) -> int:
        """
        Calcula el porcentaje de avance seg√∫n el estado

        Args:
            estatus: Estado normalizado

        Returns:
            Porcentaje (0-100)
        """
        for enum_value, porcentaje in PORCENTAJE_POR_ESTADO.items():
            if estatus == enum_value.value:
                return porcentaje
        return 0

    def _parse_fecha(self, fecha_valor) -> Optional[datetime]:
        """
        Parsea fecha de m√∫ltiples formatos

        Args:
            fecha_valor: String de fecha, objeto datetime, o pandas Timestamp

        Returns:
            datetime o None
        """
        if pd.isna(fecha_valor) or not fecha_valor:
            return None

        # Si ya es datetime
        if isinstance(fecha_valor, (datetime, pd.Timestamp)):
            return fecha_valor if isinstance(fecha_valor, datetime) else fecha_valor.to_pydatetime()

        # Intentar m√∫ltiples formatos
        formatos = [
            '%Y-%m-%d %H:%M:%S',
            '%Y-%m-%d',
            '%d/%m/%Y %H:%M:%S',
            '%d/%m/%Y',
            '%m/%d/%Y %H:%M:%S',
            '%m/%d/%Y',
            '%Y/%m/%d',
            '%d-%m-%Y'
        ]

        fecha_str = str(fecha_valor).strip()

        for formato in formatos:
            try:
                return datetime.strptime(fecha_str, formato)
            except:
                continue

        logger.warning(f"‚ö†Ô∏è  No se pudo parsear fecha: {fecha_valor}")
        return None

    # ========================================================================
    # PRECARGA DE DATOS (Optimizaci√≥n - Evita N+1 queries)
    # ========================================================================

    def _precargar_modulos(self):
        """Precarga m√≥dulos en cach√©"""
        if self._cache_modulos:
            return  # Ya est√° cargado

        query = "SELECT IdModulo, NombreModulo FROM instituto_Modulo WHERE Activo = 1"
        self.cursor.execute(query)

        for row in self.cursor.fetchall():
            self._cache_modulos[row.NombreModulo] = row.IdModulo

        logger.info(f"‚úÖ M√≥dulos precargados: {len(self._cache_modulos)}")

    def _precargar_unidades_negocio(self):
        """Precarga unidades de negocio"""
        if self._cache_unidades:
            return

        query = "SELECT IdUnidadDeNegocio, NombreUnidad FROM instituto_UnidadDeNegocio WHERE Activo = 1"
        self.cursor.execute(query)

        for row in self.cursor.fetchall():
            self._cache_unidades[row.NombreUnidad] = row.IdUnidadDeNegocio

        logger.info(f"‚úÖ Unidades de negocio precargadas: {len(self._cache_unidades)}")

    def _precargar_departamentos(self):
        """Precarga departamentos con clave (IdUnidad, NombreDepto)"""
        if self._cache_departamentos:
            return

        query = """
            SELECT IdDepartamento, IdUnidadDeNegocio, NombreDepartamento
            FROM instituto_Departamento
            WHERE Activo = 1
        """
        self.cursor.execute(query)

        for row in self.cursor.fetchall():
            key = (row.IdUnidadDeNegocio, row.NombreDepartamento)
            self._cache_departamentos[key] = row.IdDepartamento

        logger.info(f"‚úÖ Departamentos precargados: {len(self._cache_departamentos)}")

    def _precargar_usuarios(self, user_ids: List[str]):
        """
        Precarga usuarios existentes

        Args:
            user_ids: Lista de UserIds a precargar
        """
        if not user_ids:
            return

        # SQL Server usa ? como placeholder
        placeholders = ','.join(['?'] * len(user_ids))
        query = f"""
            SELECT IdUsuario, UserId
            FROM instituto_Usuario
            WHERE UserId IN ({placeholders})
        """

        self.cursor.execute(query, user_ids)

        for row in self.cursor.fetchall():
            self._cache_usuarios[row.UserId] = row.IdUsuario

        logger.info(f"‚úÖ Usuarios precargados: {len(self._cache_usuarios)}")

    def _precargar_progresos(self, user_ids: List[str]):
        """
        Precarga progresos existentes

        Args:
            user_ids: Lista de UserIds
        """
        if not user_ids:
            return

        placeholders = ','.join(['?'] * len(user_ids))
        query = f"""
            SELECT UserId, IdModulo, IdInscripcion
            FROM instituto_ProgresoModulo
            WHERE UserId IN ({placeholders})
        """

        self.cursor.execute(query, user_ids)

        for row in self.cursor.fetchall():
            key = (row.UserId, row.IdModulo)
            self._cache_progresos[key] = row.IdInscripcion

        logger.info(f"‚úÖ Progresos existentes precargados: {len(self._cache_progresos)}")

    def _precargar_evaluaciones(self):
        """Precarga evaluaciones por m√≥dulo"""
        if self._cache_evaluaciones:
            return

        query = """
            SELECT IdEvaluacion, IdModulo
            FROM instituto_Evaluacion
            WHERE Activo = 1
        """
        self.cursor.execute(query)

        for row in self.cursor.fetchall():
            # Solo guarda la primera evaluaci√≥n por m√≥dulo
            if row.IdModulo not in self._cache_evaluaciones:
                self._cache_evaluaciones[row.IdModulo] = row.IdEvaluacion

        logger.info(f"‚úÖ Evaluaciones precargadas: {len(self._cache_evaluaciones)}")

    # ========================================================================
    # CARGA: AUTO-CREACI√ìN DE ENTIDADES
    # ========================================================================

    def _crear_modulo_si_no_existe(self, num_modulo: int) -> int:
        """
        Crea un m√≥dulo nuevo si no existe (AUTO-DETECCI√ìN)

        Args:
            num_modulo: N√∫mero del m√≥dulo (1-14)

        Returns:
            IdModulo
        """
        nombre_modulo = MODULOS_MAPPING.get(num_modulo)

        if not nombre_modulo:
            logger.warning(f"‚ö†Ô∏è  N√∫mero de m√≥dulo desconocido: {num_modulo}")
            return None

        # Verificar si ya existe en cach√©
        if nombre_modulo in self._cache_modulos:
            return self._cache_modulos[nombre_modulo]

        # Verificar si existe en BD
        self.cursor.execute(
            "SELECT IdModulo FROM instituto_Modulo WHERE NombreModulo = ?",
            (nombre_modulo,)
        )
        row = self.cursor.fetchone()

        if row:
            id_modulo = row.IdModulo
            self._cache_modulos[nombre_modulo] = id_modulo
            return id_modulo

        # Crear nuevo m√≥dulo
        logger.info(f"üÜï Creando nuevo m√≥dulo: {nombre_modulo}")

        self.cursor.execute("""
            INSERT INTO instituto_Modulo
            (NombreModulo, TipoDeCapacitacion, Activo, FechaCreacion)
            VALUES (?, ?, 1, GETDATE())
        """, (nombre_modulo, TipoCapacitacion.CURRICULUM.value))

        # SQL Server devuelve lastrowid diferente
        self.cursor.execute("SELECT @@IDENTITY AS id")
        id_modulo = self.cursor.fetchone().id

        self._cache_modulos[nombre_modulo] = id_modulo
        self.stats['modulos_creados'] += 1

        # Crear evaluaci√≥n por defecto para el m√≥dulo
        self._crear_evaluacion_para_modulo(id_modulo, nombre_modulo)

        return id_modulo

    def _crear_evaluacion_para_modulo(self, id_modulo: int, nombre_modulo: str):
        """
        Crea evaluaci√≥n por defecto para un m√≥dulo

        Args:
            id_modulo: ID del m√≥dulo
            nombre_modulo: Nombre del m√≥dulo
        """
        nombre_evaluacion = f"Evaluaci√≥n {nombre_modulo}"

        self.cursor.execute("""
            INSERT INTO instituto_Evaluacion
            (IdModulo, NombreEvaluacion, TipoEvaluacion,
             PuntajeMinimo, IntentosPermitid, Activo, FechaCreacion)
            VALUES (?, ?, ?, ?, ?, 1, GETDATE())
        """, (
            id_modulo,
            nombre_evaluacion,
            TipoCapacitacion.PRUEBA.value,
            self.config.default_puntaje_minimo,
            self.config.default_intentos_permitidos
        ))

        self.stats['evaluaciones_creadas'] += 1
        logger.info(f"‚úÖ Evaluaci√≥n creada para m√≥dulo {id_modulo}")

    def _obtener_o_crear_unidad_negocio(self, nombre_unidad: str) -> Optional[int]:
        """
        Obtiene o crea una unidad de negocio

        Args:
            nombre_unidad: Nombre de la unidad

        Returns:
            IdUnidadDeNegocio
        """
        if not nombre_unidad or pd.isna(nombre_unidad):
            return None

        nombre_unidad = str(nombre_unidad).strip()

        # Verificar cach√©
        if nombre_unidad in self._cache_unidades:
            return self._cache_unidades[nombre_unidad]

        # Verificar BD
        self.cursor.execute(
            "SELECT IdUnidadDeNegocio FROM instituto_UnidadDeNegocio WHERE NombreUnidad = ?",
            (nombre_unidad,)
        )
        row = self.cursor.fetchone()

        if row:
            id_unidad = row.IdUnidadDeNegocio
            self._cache_unidades[nombre_unidad] = id_unidad
            return id_unidad

        # Crear nueva
        codigo = nombre_unidad[:20].upper().replace(' ', '_')

        self.cursor.execute("""
            INSERT INTO instituto_UnidadDeNegocio
            (NombreUnidad, Codigo, Activo, FechaCreacion)
            VALUES (?, ?, 1, GETDATE())
        """, (nombre_unidad, codigo))

        self.cursor.execute("SELECT @@IDENTITY AS id")
        id_unidad = self.cursor.fetchone().id

        self._cache_unidades[nombre_unidad] = id_unidad
        self.stats['unidades_creadas'] += 1

        logger.info(f"üÜï Unidad de negocio creada: {nombre_unidad}")

        return id_unidad

    def _obtener_o_crear_departamento(self, id_unidad: int, nombre_depto: str) -> Optional[int]:
        """
        Obtiene o crea un departamento

        Args:
            id_unidad: ID de la unidad de negocio
            nombre_depto: Nombre del departamento

        Returns:
            IdDepartamento
        """
        if not nombre_depto or pd.isna(nombre_depto) or not id_unidad:
            return None

        nombre_depto = str(nombre_depto).strip()
        key = (id_unidad, nombre_depto)

        # Verificar cach√©
        if key in self._cache_departamentos:
            return self._cache_departamentos[key]

        # Verificar BD
        self.cursor.execute("""
            SELECT IdDepartamento
            FROM instituto_Departamento
            WHERE IdUnidadDeNegocio = ? AND NombreDepartamento = ?
        """, (id_unidad, nombre_depto))
        row = self.cursor.fetchone()

        if row:
            id_depto = row.IdDepartamento
            self._cache_departamentos[key] = id_depto
            return id_depto

        # Crear nuevo
        self.cursor.execute("""
            INSERT INTO instituto_Departamento
            (IdUnidadDeNegocio, NombreDepartamento, Activo, FechaCreacion)
            VALUES (?, ?, 1, GETDATE())
        """, (id_unidad, nombre_depto))

        self.cursor.execute("SELECT @@IDENTITY AS id")
        id_depto = self.cursor.fetchone().id

        self._cache_departamentos[key] = id_depto
        self.stats['departamentos_creados'] += 1

        logger.info(f"üÜï Departamento creado: {nombre_depto} (Unidad: {id_unidad})")

        return id_depto

    # ========================================================================
    # PROCESAMIENTO: ORG PLANNING (USUARIOS)
    # ========================================================================

    def importar_org_planning(self, archivo_excel: str) -> Dict[str, Any]:
        """
        Importa archivo CSOD Org Planning (Datos de Usuarios)

        Args:
            archivo_excel: Ruta al archivo Excel

        Returns:
            Estad√≠sticas de la importaci√≥n
        """
        logger.info("="*80)
        logger.info("üë• IMPORTANDO ORG PLANNING (DATOS DE USUARIOS)")
        logger.info("="*80)

        self.stats['tiempo_inicio'] = datetime.now()

        try:
            # 1. EXTRACCI√ìN
            logger.info("\nüìñ Paso 1/4: Leyendo archivo Excel...")
            df = self._leer_excel_con_deteccion_headers(archivo_excel)
            logger.info(f"‚úÖ Registros le√≠dos: {len(df):,}")

            # 2. DETECCI√ìN DE COLUMNAS
            logger.info("\nüîç Paso 2/4: Detectando columnas...")
            self._detectar_columnas(df)

            # Verificar columna cr√≠tica
            if 'user_id' not in self.detected_columns:
                raise ValueError("‚ùå Columna 'user_id' no encontrada. No se puede continuar.")

            # 3. PRECARGA DE DATOS
            logger.info("\n‚ö° Paso 3/4: Precargando datos para optimizaci√≥n...")
            self._precargar_unidades_negocio()
            self._precargar_departamentos()

            user_ids = df[self.detected_columns['user_id']].astype(str).str.strip().unique().tolist()
            self._precargar_usuarios(user_ids)

            # 4. PROCESAMIENTO
            logger.info(f"\nüìä Paso 4/4: Procesando {len(df):,} usuarios...")
            self._procesar_usuarios_batch(df)

            # COMMIT
            self.connection.commit()
            logger.info("‚úÖ Transacci√≥n confirmada")

            self.stats['tiempo_fin'] = datetime.now()
            self._mostrar_estadisticas()

            return self.stats

        except Exception as e:
            logger.error(f"‚ùå Error en importaci√≥n Org Planning: {e}")
            self.connection.rollback()
            logger.info("üîÑ Transacci√≥n revertida")
            self.stats['errores'].append(f"Error fatal: {e}")
            raise

    def _procesar_usuarios_batch(self, df: pd.DataFrame):
        """
        Procesa usuarios en batch (INSERT/UPDATE)

        Args:
            df: DataFrame con datos de usuarios
        """
        col_user_id = self.detected_columns['user_id']
        col_nombre = self.detected_columns.get('full_name')
        col_email = self.detected_columns.get('email')
        col_cargo = self.detected_columns.get('position')
        col_unidad = self.detected_columns.get('business_unit')
        col_depto = self.detected_columns.get('department')
        col_ubicacion = self.detected_columns.get('location')
        col_nivel = self.detected_columns.get('level')

        batch_updates = []
        batch_inserts = []

        for idx, row in df.iterrows():
            try:
                user_id = str(row[col_user_id]).strip()

                if not user_id:
                    continue

                # Extraer datos
                nombre_completo = str(row[col_nombre]) if col_nombre and not pd.isna(row.get(col_nombre)) else None
                email = str(row[col_email]) if col_email and not pd.isna(row.get(col_email)) else None
                cargo = str(row[col_cargo]) if col_cargo and not pd.isna(row.get(col_cargo)) else None
                ubicacion = str(row[col_ubicacion]) if col_ubicacion and not pd.isna(row.get(col_ubicacion)) else None
                nivel = str(row[col_nivel]) if col_nivel and not pd.isna(row.get(col_nivel)) else None

                # Obtener/crear unidad y departamento
                nombre_unidad = str(row[col_unidad]) if col_unidad and not pd.isna(row.get(col_unidad)) else None
                nombre_depto = str(row[col_depto]) if col_depto and not pd.isna(row.get(col_depto)) else None

                id_unidad = self._obtener_o_crear_unidad_negocio(nombre_unidad) if nombre_unidad else None
                id_depto = self._obtener_o_crear_departamento(id_unidad, nombre_depto) if nombre_depto and id_unidad else None

                # Verificar si existe
                if user_id in self._cache_usuarios:
                    # UPDATE
                    batch_updates.append((
                        nombre_completo,
                        email,
                        cargo,
                        id_unidad,
                        id_depto,
                        nivel,
                        ubicacion,
                        user_id
                    ))
                else:
                    # INSERT
                    batch_inserts.append((
                        user_id,
                        id_unidad,
                        id_depto,
                        self.config.default_rol_id,
                        nombre_completo,
                        email,
                        cargo,
                        nivel,
                        ubicacion
                    ))

            except Exception as e:
                error_msg = f"Error en fila {idx} (UserId: {user_id if 'user_id' in locals() else 'N/A'}): {e}"
                self.stats['errores'].append(error_msg)
                logger.warning(f"‚ö†Ô∏è  {error_msg}")

        # Ejecutar BATCH UPDATES
        if batch_updates:
            self.cursor.executemany("""
                UPDATE instituto_Usuario
                SET NombreCompleto = ?,
                    UserEmail = ?,
                    Position = ?,
                    IdUnidadDeNegocio = ?,
                    IdDepartamento = ?,
                    Nivel = ?,
                    Ubicacion = ?
                WHERE UserId = ?
            """, batch_updates)

            self.stats['usuarios_actualizados'] = len(batch_updates)
            logger.info(f"‚úÖ Usuarios actualizados: {len(batch_updates):,}")

        # Ejecutar BATCH INSERTS
        if batch_inserts:
            self.cursor.executemany("""
                INSERT INTO instituto_Usuario
                (UserId, IdUnidadDeNegocio, IdDepartamento, IdRol,
                 NombreCompleto, UserEmail, Position, Nivel, Ubicacion, UserStatus, FechaCreacion)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, 'Active', GETDATE())
            """, batch_inserts)

            self.stats['usuarios_nuevos'] = len(batch_inserts)
            logger.info(f"‚úÖ Usuarios nuevos: {len(batch_inserts):,}")

    # ========================================================================
    # PROCESAMIENTO: TRAINING REPORT (PROGRESO Y CALIFICACIONES)
    # ========================================================================

    def importar_training_report(self, archivo_excel: str) -> Dict[str, Any]:
        """
        Importa archivo Enterprise Training Report (Progreso y Calificaciones)

        Args:
            archivo_excel: Ruta al archivo Excel

        Returns:
            Estad√≠sticas de la importaci√≥n
        """
        logger.info("="*80)
        logger.info("üìä IMPORTANDO TRAINING REPORT (PROGRESO Y CALIFICACIONES)")
        logger.info("="*80)

        self.stats['tiempo_inicio'] = datetime.now()

        try:
            # 1. EXTRACCI√ìN
            logger.info("\nüìñ Paso 1/5: Leyendo archivo Excel...")
            df = self._leer_excel_con_deteccion_headers(archivo_excel)
            logger.info(f"‚úÖ Registros le√≠dos: {len(df):,}")

            # 2. DETECCI√ìN DE COLUMNAS
            logger.info("\nüîç Paso 2/5: Detectando columnas...")
            self._detectar_columnas(df)

            # Verificar columnas cr√≠ticas
            if 'user_id' not in self.detected_columns or 'training_title' not in self.detected_columns:
                raise ValueError("‚ùå Columnas cr√≠ticas no encontradas (user_id, training_title)")

            # 3. PRECARGA DE DATOS
            logger.info("\n‚ö° Paso 3/5: Precargando datos para optimizaci√≥n...")
            self._precargar_modulos()
            self._precargar_evaluaciones()

            user_ids = df[self.detected_columns['user_id']].astype(str).str.strip().unique().tolist()
            self._precargar_usuarios(user_ids)
            self._precargar_progresos(user_ids)

            # 4. PROCESAMIENTO DE M√ìDULOS
            logger.info("\nüìã Paso 4/5: Procesando progreso de m√≥dulos...")
            self._procesar_modulos_batch(df)

            # 5. PROCESAMIENTO DE CALIFICACIONES
            logger.info("\nüìù Paso 5/5: Procesando calificaciones de evaluaciones...")
            self._procesar_calificaciones_batch(df)

            # COMMIT
            self.connection.commit()
            logger.info("‚úÖ Transacci√≥n confirmada")

            self.stats['tiempo_fin'] = datetime.now()
            self._mostrar_estadisticas()

            return self.stats

        except Exception as e:
            logger.error(f"‚ùå Error en importaci√≥n Training Report: {e}")
            self.connection.rollback()
            logger.info("üîÑ Transacci√≥n revertida")
            self.stats['errores'].append(f"Error fatal: {e}")
            raise

    def _procesar_modulos_batch(self, df: pd.DataFrame):
        """
        Procesa progreso de m√≥dulos en batch

        Args:
            df: DataFrame con datos de training
        """
        col_user_id = self.detected_columns['user_id']
        col_titulo = self.detected_columns['training_title']
        col_tipo = self.detected_columns.get('training_type')
        col_estado = self.detected_columns.get('record_status')
        col_fecha_inicio = self.detected_columns.get('start_date')
        col_fecha_fin = self.detected_columns.get('completion_date')
        col_fecha_registro = self.detected_columns.get('transcript_date')

        # Filtrar solo m√≥dulos (no pruebas)
        df_modulos = df[df[col_titulo].str.contains('M√ìDULO|MODULE', case=False, na=False, regex=True)].copy()

        if len(df_modulos) == 0:
            logger.info("‚ÑπÔ∏è  No se encontraron m√≥dulos en el archivo")
            return

        logger.info(f"üìä Registros de m√≥dulos a procesar: {len(df_modulos):,}")

        batch_updates = []
        batch_inserts = []

        modulos_no_identificados = set()

        for idx, row in df_modulos.iterrows():
            try:
                user_id = str(row[col_user_id]).strip()
                titulo = row[col_titulo]

                # Identificar m√≥dulo
                num_modulo = self._extraer_numero_modulo(titulo)

                if not num_modulo:
                    # Intentar fuzzy matching
                    num_modulo = self._identificar_modulo_fuzzy(titulo)

                if not num_modulo:
                    if titulo not in modulos_no_identificados:
                        modulos_no_identificados.add(titulo)
                        logger.warning(f"‚ö†Ô∏è  No se pudo identificar m√≥dulo: '{titulo}'")
                    continue

                # Obtener/crear m√≥dulo
                id_modulo = self._crear_modulo_si_no_existe(num_modulo)

                if not id_modulo:
                    continue

                # Parsear fechas
                fecha_inicio = self._parse_fecha(row.get(col_fecha_inicio)) if col_fecha_inicio else None
                fecha_fin = self._parse_fecha(row.get(col_fecha_fin)) if col_fecha_fin else None
                fecha_registro = self._parse_fecha(row.get(col_fecha_registro)) if col_fecha_registro else None

                # Normalizar estado
                estado_excel = row.get(col_estado, '') if col_estado else ''
                estado = self._normalizar_estatus(estado_excel)
                porcentaje = self._calcular_porcentaje_por_estado(estado)

                # Verificar si existe progreso
                key = (user_id, id_modulo)

                if key in self._cache_progresos:
                    # UPDATE
                    batch_updates.append((
                        estado,
                        fecha_inicio or fecha_registro,
                        fecha_fin,
                        porcentaje,
                        user_id,
                        id_modulo
                    ))
                else:
                    # INSERT
                    batch_inserts.append((
                        user_id,
                        id_modulo,
                        estado,
                        fecha_inicio or fecha_registro or datetime.now(),
                        fecha_fin,
                        porcentaje,
                        datetime.now()
                    ))

            except Exception as e:
                error_msg = f"Error en fila {idx}: {e}"
                self.stats['errores'].append(error_msg)
                logger.warning(f"‚ö†Ô∏è  {error_msg}")

        # Ejecutar BATCH UPDATES
        if batch_updates:
            self.cursor.executemany("""
                UPDATE instituto_ProgresoModulo
                SET EstatusModulo = ?,
                    FechaInicio = COALESCE(?, FechaInicio),
                    FechaFinalizacion = ?,
                    PorcentajeAvance = ?
                WHERE UserId = ? AND IdModulo = ?
            """, batch_updates)

            self.stats['progresos_actualizados'] = len(batch_updates)
            logger.info(f"‚úÖ Progresos actualizados: {len(batch_updates):,}")

        # Ejecutar BATCH INSERTS
        if batch_inserts:
            self.cursor.executemany("""
                INSERT INTO instituto_ProgresoModulo
                (UserId, IdModulo, EstatusModulo, FechaInicio, FechaFinalizacion,
                 PorcentajeAvance, FechaAsignacion)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, batch_inserts)

            self.stats['progresos_insertados'] = len(batch_inserts)
            logger.info(f"‚úÖ Progresos insertados: {len(batch_inserts):,}")

    def _procesar_calificaciones_batch(self, df: pd.DataFrame):
        """
        Procesa calificaciones de evaluaciones en batch

        Args:
            df: DataFrame con datos de training
        """
        col_user_id = self.detected_columns['user_id']
        col_titulo = self.detected_columns['training_title']
        col_tipo = self.detected_columns.get('training_type')
        col_puntaje = self.detected_columns.get('score')

        if not col_tipo or not col_puntaje:
            logger.info("‚ÑπÔ∏è  Columnas de tipo o puntaje no encontradas. Saltando calificaciones.")
            return

        # Filtrar solo pruebas/evaluaciones
        df_pruebas = df[
            df[col_tipo].str.contains('Prueba|Test|Assessment|Exam', case=False, na=False, regex=True)
        ].copy()

        if len(df_pruebas) == 0:
            logger.info("‚ÑπÔ∏è  No se encontraron evaluaciones en el archivo")
            return

        logger.info(f"üìä Calificaciones a procesar: {len(df_pruebas):,}")

        calificaciones_registradas = 0

        for idx, row in df_pruebas.iterrows():
            try:
                user_id = str(row[col_user_id]).strip()
                titulo = row[col_titulo]
                puntaje = row.get(col_puntaje)

                if pd.isna(puntaje):
                    continue

                try:
                    puntaje_decimal = float(puntaje)
                except:
                    continue

                # Identificar m√≥dulo
                num_modulo = self._extraer_numero_modulo(titulo)

                if not num_modulo:
                    num_modulo = self._identificar_modulo_fuzzy(titulo)

                if not num_modulo:
                    continue

                # Obtener/crear m√≥dulo
                id_modulo = self._crear_modulo_si_no_existe(num_modulo)

                if not id_modulo:
                    continue

                # Obtener IdInscripcion
                key = (user_id, id_modulo)
                id_inscripcion = self._cache_progresos.get(key)

                if not id_inscripcion:
                    logger.warning(f"‚ö†Ô∏è  No se encontr√≥ inscripci√≥n para {user_id} - M√≥dulo {id_modulo}")
                    continue

                # Obtener/crear evaluaci√≥n
                id_evaluacion = self._cache_evaluaciones.get(id_modulo)

                if not id_evaluacion:
                    # Crear evaluaci√≥n
                    nombre_modulo = MODULOS_MAPPING.get(num_modulo)
                    self._crear_evaluacion_para_modulo(id_modulo, nombre_modulo)

                    # Actualizar cach√©
                    self.cursor.execute("""
                        SELECT IdEvaluacion
                        FROM instituto_Evaluacion
                        WHERE IdModulo = ? AND Activo = 1
                    """, (id_modulo,))
                    row_eval = self.cursor.fetchone()

                    if row_eval:
                        id_evaluacion = row_eval.IdEvaluacion
                        self._cache_evaluaciones[id_modulo] = id_evaluacion

                # Obtener puntaje m√≠nimo
                self.cursor.execute("""
                    SELECT PuntajeMinimo
                    FROM instituto_Evaluacion
                    WHERE IdEvaluacion = ?
                """, (id_evaluacion,))
                row_eval = self.cursor.fetchone()
                puntaje_minimo = row_eval.PuntajeMinimo if row_eval else self.config.default_puntaje_minimo

                # Determinar si aprob√≥
                aprobado = 1 if puntaje_decimal >= puntaje_minimo else 0

                # Contar intentos previos
                self.cursor.execute("""
                    SELECT COUNT(*) as total
                    FROM instituto_ResultadoEvaluacion
                    WHERE IdInscripcion = ? AND IdEvaluacion = ?
                """, (id_inscripcion, id_evaluacion))

                intento_numero = self.cursor.fetchone().total + 1

                # Insertar resultado
                self.cursor.execute("""
                    INSERT INTO instituto_ResultadoEvaluacion
                    (IdInscripcion, IdEvaluacion, PuntajeObtenido, Aprobado,
                     IntentoNumero, FechaRealizacion)
                    VALUES (?, ?, ?, ?, ?, GETDATE())
                """, (id_inscripcion, id_evaluacion, puntaje_decimal, aprobado, intento_numero))

                calificaciones_registradas += 1

                # Si aprob√≥, actualizar progreso a Terminado
                if aprobado:
                    self.cursor.execute("""
                        UPDATE instituto_ProgresoModulo
                        SET EstatusModulo = 'Terminado',
                            PorcentajeAvance = 100,
                            FechaFinalizacion = GETDATE()
                        WHERE IdInscripcion = ?
                    """, (id_inscripcion,))

            except Exception as e:
                error_msg = f"Error en calificaci√≥n {idx}: {e}"
                self.stats['errores'].append(error_msg)
                logger.warning(f"‚ö†Ô∏è  {error_msg}")

        self.stats['calificaciones_registradas'] = calificaciones_registradas
        logger.info(f"‚úÖ Calificaciones registradas: {calificaciones_registradas:,}")

    # ========================================================================
    # REPORTES Y ESTAD√çSTICAS
    # ========================================================================

    def _mostrar_estadisticas(self):
        """Muestra estad√≠sticas finales de la importaci√≥n"""
        logger.info("\n" + "="*80)
        logger.info("üìä ESTAD√çSTICAS FINALES DE LA IMPORTACI√ìN")
        logger.info("="*80)

        tiempo_total = None
        if self.stats['tiempo_inicio'] and self.stats['tiempo_fin']:
            tiempo_total = self.stats['tiempo_fin'] - self.stats['tiempo_inicio']
            logger.info(f"\n‚è±Ô∏è  Tiempo total: {tiempo_total}")

        logger.info("\nüë• USUARIOS:")
        logger.info(f"  ‚Ä¢ Nuevos:               {self.stats['usuarios_nuevos']:,}")
        logger.info(f"  ‚Ä¢ Actualizados:         {self.stats['usuarios_actualizados']:,}")

        logger.info("\nüìã M√ìDULOS Y PROGRESO:")
        logger.info(f"  ‚Ä¢ M√≥dulos creados:      {self.stats['modulos_creados']:,}")
        logger.info(f"  ‚Ä¢ Progresos insertados: {self.stats['progresos_insertados']:,}")
        logger.info(f"  ‚Ä¢ Progresos actualizados: {self.stats['progresos_actualizados']:,}")

        logger.info("\nüìù EVALUACIONES:")
        logger.info(f"  ‚Ä¢ Evaluaciones creadas: {self.stats['evaluaciones_creadas']:,}")
        logger.info(f"  ‚Ä¢ Calificaciones registradas: {self.stats['calificaciones_registradas']:,}")

        logger.info("\nüè¢ ORGANIZACI√ìN:")
        logger.info(f"  ‚Ä¢ Unidades creadas:     {self.stats['unidades_creadas']:,}")
        logger.info(f"  ‚Ä¢ Departamentos creados: {self.stats['departamentos_creados']:,}")

        logger.info(f"\n‚ùå ERRORES:")
        logger.info(f"  ‚Ä¢ Total:                {len(self.stats['errores']):,}")

        if self.stats['errores']:
            logger.info("\n‚ö†Ô∏è  PRIMEROS 10 ERRORES:")
            for i, error in enumerate(self.stats['errores'][:10], 1):
                logger.info(f"  {i}. {error}")

            if len(self.stats['errores']) > 10:
                logger.info(f"  ... y {len(self.stats['errores']) - 10:,} errores m√°s")

        logger.info("\n" + "="*80)
        logger.info("‚úÖ IMPORTACI√ìN COMPLETADA")
        logger.info("="*80)


# ============================================================================
# FUNCI√ìN PRINCIPAL DE USO
# ============================================================================

def main():
    """
    Ejemplo de uso del ETL
    """
    # Configuraci√≥n
    config = ETLConfig(
        server="localhost",
        database="InstitutoHutchison",
        username=None,  # None = Windows Authentication
        password=None,
        batch_size=1000,
        enable_validation=True,
        auto_create_modules=True
    )

    # Crear instancia del ETL
    with ETLInstitutoCompleto(config) as etl:
        # Importar Org Planning (usuarios)
        etl.importar_org_planning("path/to/CSOD_Data_Source_for_Org_Planning.xlsx")

        # Importar Training Report (progreso y calificaciones)
        etl.importar_training_report("path/to/Enterprise_Training_Report.xlsx")


if __name__ == "__main__":
    main()
